{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYRx0BPkrSezAfkQi+k1pa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bbZCmZA4TqLW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","import os\n","import numpy as np\n","import random\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","source":["# 버전 명 입력\n","version_name = 'Mobile+G_128_dropout'"],"metadata":{"id":"sfu320IJU2LY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Hyperparameter Settings\"\"\"\n","\n","CFG = {\n","    'IMG_SIZE': 128,  # 224\n","    'EPOCHS': 10,\n","    'LR': 0.01,\n","    'BATCH_SIZE' : 32,  #64\n","    'SEED': 41\n","}\n","\n","\"\"\"## Fixed Random-Seed\"\"\"\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True  # False : Disable CUDA benchmarks\n","\n","seed_everything(CFG['SEED'])  # Seed 고정"],"metadata":{"id":"qpzgfmr8T7rz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gpu 활용 여부 출력\n","if torch.cuda.is_available() : device = torch.device('cuda')\n","else : device=torch.device('cpu')\n","print(f'Using {device}')"],"metadata":{"id":"rsQp6uBGUABJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Load Data\"\"\"\n","\n","# Real Data\n","train_data = pd.read_csv('./train.csv')\n","test_data = pd.read_csv('./test.csv')\n","\n","\n","print('raw train data shape : ', train_data.shape)\n","print('raw test data shape : ', test_data.shape)"],"metadata":{"id":"t6TCd3LlUGUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Custom Dataset\"\"\"\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.dataframe = dataframe\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.dataframe.iloc[idx]['img_path']\n","        img = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        # mos column 존재 여부에 따라 값을 설정\n","        mos = float(self.dataframe.iloc[idx]['mos']) if 'mos' in self.dataframe.columns else 0.0\n","        comment = self.dataframe.iloc[idx]['comments'] if 'comments' in self.dataframe.columns else \"\"\n","\n","        return img, mos, comment\n"],"metadata":{"id":"KTh1AzBOUKdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Define Model\"\"\"\n","\n","class BaseModel(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512, dropout=0.5):\n","        super(BaseModel, self).__init__()\n","        self.cnn_backbone = models.mobilenet_v3_small(pretrained=True)\n","\n","        # Remove the last fully connected layer to get features\n","        modules = list(self.cnn_backbone.children())[:-1]\n","        self.cnn = nn.Sequential(*modules)\n","        self.regression_head = nn.Linear(576, 1)\n","\n","        # Captioning head\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.gru = nn.GRU(embed_dim+576, hidden_dim)\n","\n","        # Dropout 레이어 추가\n","        self.dropout = nn.Dropout(p=dropout)\n","        # 최종 예측을 위한 선형 레이어\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, images, captions=None):\n","        # CNN\n","        features = self.cnn(images)\n","        features_flat = features.view(features.size(0), -1)\n","\n","        # Image quality regression\n","        mos = self.regression_head(features_flat)\n","\n","        # gru captioning\n","        if captions is not None:\n","            embeddings = self.embedding(captions)\n","\n","            # Concatenate image features and embeddings for each word in the captions\n","            combined = torch.cat([features_flat.unsqueeze(1).repeat(1, embeddings.size(1), 1), embeddings], dim=2)\n","\n","            # Caption Layer에 Dropout 추가\n","            combined = self.dropout(combined)\n","\n","            gru_out, _ = self.gru(combined)\n","            outputs = self.fc(gru_out)\n","\n","            return mos, outputs\n","        else:\n","            return mos, None\n"],"metadata":{"id":"sL22FxNuUU0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 단어 사전 생성\n","all_comments = ' '.join(train_data['comments']).split()\n","vocab = set(all_comments)\n","vocab = ['<PAD>', '<SOS>', '<EOS>'] + list(vocab)\n","word2idx = {word: idx for idx, word in enumerate(vocab)}\n","idx2word = {idx: word for word, idx in word2idx.items()}\n","\n","\n","# 데이터셋 및 DataLoader 생성\n","transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor()\n","])\n","\n","train_dataset = CustomDataset(train_data, transform)\n","train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, pin_memory=True)\n","\n","\n","# 모델, 손실함수, 옵티마이저\n","model = BaseModel(len(vocab)).cuda()\n","\n","criterion1 = nn.MSELoss()\n","criterion2 = nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])\n","optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])"],"metadata":{"id":"ad9ocn8TUZGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습\n","model.train()\n","\n","for epoch in range(CFG['EPOCHS']):\n","    total_loss = 0\n","    loop = tqdm(train_loader, leave=True)\n","    for imgs, mos, comments in loop:\n","        imgs, mos = imgs.float().cuda(), mos.float().cuda()\n","\n","        # Batch Preprocessing\n","        comments_tensor = torch.zeros((len(comments), len(max(comments, key=len)))).long().cuda()\n","        for i, comment in enumerate(comments):\n","            tokenized = ['<SOS>'] + comment.split() + ['<EOS>']\n","            comments_tensor[i, :len(tokenized)] = torch.tensor([word2idx[word] for word in tokenized])\n","\n","        # Forward & Loss\n","        predicted_mos, predicted_comments = model(imgs, comments_tensor)\n","        loss1 = criterion1(predicted_mos.squeeze(1), mos)\n","        loss2 = criterion2(predicted_comments.view(-1, len(vocab)), comments_tensor.view(-1))\n","        loss = loss1 + loss2\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        loop.set_description(f\"Epoch {epoch + 1}\")\n","        loop.set_postfix(loss=loss.item())\n","\n","    print(f\"Epoch {epoch + 1} finished with average loss: {total_loss / len(train_loader):.4f}\")\n"],"metadata":{"id":"-4eLbayMUeZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Inference & Submit\"\"\"\n","\n","test_dataset = CustomDataset(test_data, transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n","\n","model.eval()\n","predicted_mos_list = []\n","predicted_comments_list = []\n","\n","\n","def greedy_decode(model, image, max_length=50):\n","    image = image.unsqueeze(0).cuda()\n","    mos, _ = model(image)\n","    output_sentence = []\n","\n","    # 시작 토큰 설정\n","    current_token = torch.tensor([word2idx['<SOS>']]).cuda()\n","    hidden = None\n","    features = model.cnn(image).view(image.size(0), -1)\n","\n","    for _ in range(max_length):\n","        embeddings = model.embedding(current_token).unsqueeze(0)\n","        combined = torch.cat([features.unsqueeze(1), embeddings], dim=2)\n","        out, hidden = model.gru(combined, hidden)\n","\n","        output = model.fc(out.squeeze(0))\n","        _, current_token = torch.max(output, dim=1)\n","\n","        # <EOS> 토큰에 도달하면 멈춤\n","        if current_token.item() == word2idx['<EOS>']:\n","            break\n","\n","        # <SOS> 또는 <PAD> 토큰은 생성한 캡션에 추가하지 않음\n","        if current_token.item() not in [word2idx['<SOS>'], word2idx['<PAD>']]:\n","            output_sentence.append(idx2word[current_token.item()])\n","\n","    return mos.item(), ' '.join(output_sentence)\n","\n","# 추론 과정\n","with torch.no_grad():\n","    for imgs, _, _ in tqdm(test_loader):\n","        for img in imgs:\n","            img = img.float().cuda()\n","            mos, caption = greedy_decode(model, img)\n","            predicted_mos_list.append(mos)\n","            predicted_comments_list.append(caption)"],"metadata":{"id":"_vd0RvaFUi0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결과 저장\n","result_df = pd.DataFrame({\n","    'img_name': test_data['img_name'].astype('str'),\n","    'mos': predicted_mos_list,\n","    'comments': predicted_comments_list  # 캡션 부분은 위에서 생성한 것을 사용\n","})\n","\n","# 예측 결과에 NaN이 있다면, 제출 시 오류가 발생하므로 후처리 진행 (sample_submission.csv과 동일하게)\n","result_df['comments'] = result_df['comments'].replace('', 'Nice Image')\n","result_df.to_csv(f'./submit_{version_name}.csv', index=False)\n","\n","\n","print(\"Inference completed and results saved to ~.\")"],"metadata":{"id":"gBFUDFyXUpQ6"},"execution_count":null,"outputs":[]}]}