{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNgOB5FTeYSbSe5BQ/dNVV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bbZCmZA4TqLW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","import os\n","import numpy as np\n","import random\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","source":["# 버전 명 입력\n","version_name = 'Mobile+G_128_dropout_parallel'"],"metadata":{"id":"sfu320IJU2LY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Hyperparameter Settings\"\"\"\n","\n","CFG = {\n","    'IMG_SIZE': 128,  # 224\n","    'EPOCHS': 10,\n","    'LR': 0.01,\n","    'BATCH_SIZE' : 32,  #64\n","    'SEED': 41\n","}\n","\n","\"\"\"## Fixed Random-Seed\"\"\"\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True  # False : Disable CUDA benchmarks\n","\n","seed_everything(CFG['SEED'])  # Seed 고정"],"metadata":{"id":"qpzgfmr8T7rz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gpu 활용 여부 출력\n","if torch.cuda.is_available() : device = torch.device('cuda')\n","else : device=torch.device('cpu')\n","print(f'Using {device}')"],"metadata":{"id":"rsQp6uBGUABJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Load Data\"\"\"\n","\n","# Real Data\n","train_data = pd.read_csv('./train.csv')\n","test_data = pd.read_csv('./test.csv')\n","\n","\n","print('raw train data shape : ', train_data.shape)\n","print('raw test data shape : ', test_data.shape)"],"metadata":{"id":"t6TCd3LlUGUh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Custom Dataset\"\"\"\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.dataframe = dataframe\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.dataframe.iloc[idx]['img_path']\n","        img = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        # mos column 존재 여부에 따라 값을 설정\n","        mos = float(self.dataframe.iloc[idx]['mos']) if 'mos' in self.dataframe.columns else 0.0\n","        comment = self.dataframe.iloc[idx]['comments'] if 'comments' in self.dataframe.columns else \"\"\n","\n","        return img, mos, comment\n"],"metadata":{"id":"KTh1AzBOUKdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Define Model\"\"\"\n","\n","class BaseModel(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512, dropout=0.5):\n","        super(BaseModel, self).__init__()\n","        self.cnn_backbone = models.mobilenet_v3_small(pretrained=True)\n","\n","        # Remove the last fully connected layer to get features\n","        modules = list(self.cnn_backbone.children())[:-1]\n","        self.cnn = nn.Sequential(*modules)\n","        self.regression_head = nn.Linear(576, 1)\n","\n","        # Captioning head\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.gru = nn.GRU(embed_dim+576, hidden_dim)\n","\n","        # Dropout 레이어 추가\n","        self.dropout = nn.Dropout(p=dropout)\n","        # 최종 예측을 위한 선형 레이어\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, images, captions=None):\n","        # CNN\n","        features = self.cnn(images)\n","        features_flat = features.view(features.size(0), -1)\n","\n","        # Image quality regression\n","        mos = self.regression_head(features_flat)\n","\n","        # gru captioning\n","        if captions is not None:\n","            embeddings = self.embedding(captions)\n","\n","            # Concatenate image features and embeddings for each word in the captions\n","            combined = torch.cat([features_flat.unsqueeze(1).repeat(1, embeddings.size(1), 1), embeddings], dim=2)\n","\n","            # Caption Layer에 Dropout 추가\n","            combined = self.dropout(combined)\n","\n","            gru_out, _ = self.gru(combined)\n","            outputs = self.fc(gru_out)\n","\n","            return mos, outputs\n","        else:\n","            return mos, None\n"],"metadata":{"id":"sL22FxNuUU0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 단어 사전 생성\n","all_comments = ' '.join(train_data['comments']).split()\n","vocab = set(all_comments)\n","vocab = ['<PAD>', '<SOS>', '<EOS>'] + list(vocab)\n","word2idx = {word: idx for idx, word in enumerate(vocab)}\n","idx2word = {idx: word for word, idx in word2idx.items()}\n","\n","\n","# 데이터셋 및 DataLoader 생성\n","transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor()\n","])\n","\n","train_dataset = CustomDataset(train_data, transform)\n","train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, pin_memory=True)\n","\n","\n","# 모델, 손실함수, 옵티마이저\n","model = BaseModel(len(vocab)).to(device)\n","\n","criterion1 = nn.MSELoss()\n","criterion2 = nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])\n","optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])"],"metadata":{"id":"ad9ocn8TUZGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"Distributed Data Parallel\"\n","\n","# 모듈 불러오기\n","import threading\n","import functools\n","from torch.autograd import Variable, Function\n","import torch.cuda.comm as comm\n","from torch.nn.parallel.data_parallel import DataParallel\n","from torch.nn.parallel.parallel_apply import get_a_var\n","from torch.nn.parallel._functions import ReduceAddCoalesced, Broadcast\n","\n","torch_ver = torch.__version__[:3]\n","\n","__all__ = ['allreduce', 'DataParallelModel', 'DataParallelCriterion',\n","           'patch_replication_callback']\n","\n","# All-reduce 알고리즘 사용 : 모든 process의 array를 하나의 array로\n","def allreduce(*inputs):\n","    \"\"\"Cross GPU all reduce autograd operation for calculate mean and\n","    variance in SyncBN.\n","    \"\"\"\n","    return AllReduce.apply(*inputs)\n","\n","class AllReduce(Function):\n","    @staticmethod\n","    def forward(ctx, num_inputs, *inputs):\n","        ctx.num_inputs = num_inputs\n","        ctx.target_gpus = [inputs[i].get_device() for i in range(0, len(inputs), num_inputs)]\n","        inputs = [inputs[i:i + num_inputs]\n","                 for i in range(0, len(inputs), num_inputs)]\n","        # sort before reduce sum\n","        inputs = sorted(inputs, key=lambda i: i[0].get_device())\n","        results = comm.reduce_add_coalesced(inputs, ctx.target_gpus[0])\n","        outputs = comm.broadcast_coalesced(results, ctx.target_gpus)\n","        return tuple([t for tensors in outputs for t in tensors])\n","\n","    @staticmethod\n","    def backward(ctx, *inputs):\n","        inputs = [i.data for i in inputs]\n","        inputs = [inputs[i:i + ctx.num_inputs]\n","                 for i in range(0, len(inputs), ctx.num_inputs)]\n","        results = comm.reduce_add_coalesced(inputs, ctx.target_gpus[0])\n","        outputs = comm.broadcast_coalesced(results, ctx.target_gpus)\n","        return (None,) + tuple([Variable(t) for tensors in outputs for t in tensors])\n","\n","class Reduce(Function):\n","    @staticmethod\n","    def forward(ctx, *inputs):\n","        ctx.target_gpus = [inputs[i].get_device() for i in range(len(inputs))]\n","        inputs = sorted(inputs, key=lambda i: i.get_device())\n","        return comm.reduce_add(inputs)\n","\n","    @staticmethod\n","    def backward(ctx, gradOutput):\n","        return Broadcast.apply(ctx.target_gpus, gradOutput)\n","\n","# Data Parallel구현(gather,replicate, scater)\n","\n","class DataParallelModel(DataParallel):\n","\n","    def gather(self, outputs, output_device):\n","        return outputs\n","\n","    def replicate(self, module, device_ids):\n","        modules = super(DataParallelModel, self).replicate(module, device_ids)\n","        return modules\n","\n","\n","# 메모리 과부하 방지\n","\n","class DataParallelCriterion(DataParallel):\n","\n","    def forward(self, inputs, *targets, **kwargs):\n","        # input should be already scatterd\n","        # scattering the targets instead\n","        if not self.device_ids:\n","            return self.module(inputs, *targets, **kwargs)\n","        targets, kwargs = self.scatter(targets, kwargs, self.device_ids)\n","        if len(self.device_ids) == 1:\n","            return self.module(inputs, *targets[0], **kwargs[0])\n","        replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n","        targets = tuple(targets_per_gpu[0] for targets_per_gpu in targets)\n","        outputs = _criterion_parallel_apply(replicas, inputs, targets, kwargs)\n","        return Reduce.apply(*outputs) / len(outputs)\n","\n","\n","def _criterion_parallel_apply(modules, inputs, targets, kwargs_tup=None, devices=None):\n","    assert len(modules) == len(inputs)\n","    assert len(targets) == len(inputs)\n","    if kwargs_tup:\n","        assert len(modules) == len(kwargs_tup)\n","    else:\n","        kwargs_tup = ({},) * len(modules)\n","    if devices is not None:\n","        assert len(modules) == len(devices)\n","    else:\n","        devices = [None] * len(modules)\n","\n","    lock = threading.Lock()\n","    results = {}\n","    if torch_ver != \"0.3\":\n","        grad_enabled = torch.is_grad_enabled()\n","\n","    def _worker(i, module, input, target, kwargs, device=None):\n","        if torch_ver != \"0.3\":\n","            torch.set_grad_enabled(grad_enabled)\n","        if device is None:\n","            device = get_a_var(input).get_device()\n","        try:\n","            with torch.cuda.device(device):\n","                output = module(*(input + target), **kwargs)\n","            with lock:\n","                results[i] = output\n","        except Exception as e:\n","            with lock:\n","                results[i] = e\n","\n","    if len(modules) > 1:\n","        threads = [threading.Thread(target=_worker,\n","                                    args=(i, module, input, target,\n","                                          kwargs, device),)\n","                   for i, (module, input, target, kwargs, device) in\n","                   enumerate(zip(modules, inputs, targets, kwargs_tup, devices))]\n","\n","        for thread in threads:\n","            thread.start()\n","        for thread in threads:\n","            thread.join()\n","    else:\n","        _worker(0, modules[0], inputs[0], kwargs_tup[0], devices[0])\n","\n","    outputs = []\n","    for i in range(len(inputs)):\n","        output = results[i]\n","        if isinstance(output, Exception):\n","            raise output\n","        outputs.append(output)\n","    return outputs\n","\n","\n","# 모델 병렬처리로 감싸기\n","device = torch.device(\"cuda:0\")\n","model.to(device)\n","model = DataParallelModel(model)\n","\n","\n","criterion = nn.NLLLoss()\n","criterion = DataParallelCriterion(criterion)"],"metadata":{"id":"RpgBVM-s0YA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습\n","model.train()\n","\n","for epoch in range(CFG['EPOCHS']):\n","    total_loss = 0\n","    loop = tqdm(train_loader, leave=True)\n","    for imgs, mos, comments in loop:\n","        imgs, mos = imgs.float().to(device), mos.float().to(device)\n","\n","        # Batch Preprocessing\n","        comments_tensor = torch.zeros((len(comments), len(max(comments, key=len)))).long().to(device)\n","        for i, comment in enumerate(comments):\n","            tokenized = ['<SOS>'] + comment.split() + ['<EOS>']\n","            comments_tensor[i, :len(tokenized)] = torch.tensor([word2idx[word] for word in tokenized])\n","\n","        # Forward & Loss\n","        predicted_mos, predicted_comments = model(imgs, comments_tensor)\n","        loss1 = criterion1(predicted_mos.squeeze(1), mos)\n","        loss2 = criterion2(predicted_comments.view(-1, len(vocab)), comments_tensor.view(-1))\n","        loss = loss1 + loss2\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        loop.set_description(f\"Epoch {epoch + 1}\")\n","        loop.set_postfix(loss=loss.item())\n","\n","    print(f\"Epoch {epoch + 1} finished with average loss: {total_loss / len(train_loader):.4f}\")\n"],"metadata":{"id":"-4eLbayMUeZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"## Inference & Submit\"\"\"\n","\n","test_dataset = CustomDataset(test_data, transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n","\n","model.eval()\n","predicted_mos_list = []\n","predicted_comments_list = []\n","\n","\n","def greedy_decode(model, image, max_length=50):\n","    image = image.unsqueeze(0).cuda()\n","    mos, _ = model(image)\n","    output_sentence = []\n","\n","    # 시작 토큰 설정\n","    current_token = torch.tensor([word2idx['<SOS>']]).cuda()\n","    hidden = None\n","    features = model.module.cnn(image).view(image.size(0), -1)\n","\n","    for _ in range(max_length):\n","        embeddings = model.module.embedding(current_token).unsqueeze(0)\n","        combined = torch.cat([features.unsqueeze(1), embeddings], dim=2)\n","        out, hidden = model.module.gru(combined, hidden)\n","\n","        output = model.module.fc(out.squeeze(0))\n","        _, current_token = torch.max(output, dim=1)\n","\n","        # <EOS> 토큰에 도달하면 멈춤\n","        if current_token.item() == word2idx['<EOS>']:\n","            break\n","\n","        # <SOS> 또는 <PAD> 토큰은 생성한 캡션에 추가하지 않음\n","        if current_token.item() not in [word2idx['<SOS>'], word2idx['<PAD>']]:\n","            output_sentence.append(idx2word[current_token.item()])\n","\n","    return mos.item(), ' '.join(output_sentence)\n","\n","# 추론 과정\n","with torch.no_grad():\n","    for imgs, _, _ in tqdm(test_loader):\n","        for img in imgs:\n","            img = img.float().to(device)\n","            mos, caption = greedy_decode(model, img)\n","            predicted_mos_list.append(mos)\n","            predicted_comments_list.append(caption)"],"metadata":{"id":"_vd0RvaFUi0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결과 저장\n","result_df = pd.DataFrame({\n","    'img_name': test_data['img_name'].astype('str'),\n","    'mos': predicted_mos_list,\n","    'comments': predicted_comments_list  # 캡션 부분은 위에서 생성한 것을 사용\n","})\n","\n","# 예측 결과에 NaN이 있다면, 제출 시 오류가 발생하므로 후처리 진행 (sample_submission.csv과 동일하게)\n","result_df['comments'] = result_df['comments'].replace('', 'Nice Image')\n","result_df.to_csv(f'./submit_{version_name}.csv', index=False)\n","\n","\n","print(\"Inference completed and results saved to ~.\")"],"metadata":{"id":"gBFUDFyXUpQ6"},"execution_count":null,"outputs":[]}]}